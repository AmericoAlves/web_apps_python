{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renta de Bicicletas\n",
    "\n",
    "## Prediccion de la demanda en el alquiler de bicicletas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "from sklearn.preprocessing import PolynomialFeatures as PF\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "UCI's Bike Sharing Dataset Data Set\n",
    "[link](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset)\n",
    "\n",
    "<B>Resumen:</B> Este dataset contiene las rentas de bicicletas por hora y dia entre los años 2011 y 2012 en el sistema Capital Bikeshare con la correspondiente informacion climatologica y estacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atributos:**\n",
    "\n",
    "\n",
    "Ambos csv tienen los siguientes campos, excepto hr que no esta en day.csv\n",
    "\n",
    "- **instant**: indice\n",
    "- **dteday** : fecha\n",
    "- **season** : estacion (1:primavera, 2:verano, 3:otoño, 4:invierno)\n",
    "- **yr** : año (0: 2011, 1:2012)\n",
    "- **mnth** : mes ( 1 to 12)\n",
    "- **hr** : hora (0 to 23)\n",
    "- **holiday** : dia festivo o no\n",
    "- **weekday** : dia de la semana\n",
    "- **workingday** : dia laborable o no\n",
    "+ **weathersit** : \n",
    "    - 1: Despejado, Pocas nubes, Parcialmente nublado\n",
    "    - 2: Niebla, Niebla+Nublado\n",
    "    - 3: Nieve ligera, LLuvia ligera+Tormenta+Nube dispersa\n",
    "    - 4: LLuvia fuerte+Hielo+Tormenta+Niebla,Nieve+Niebla\n",
    "- **temp** : temperatura normalizada en grados centigrados. MinMax Scaler (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (solo en escala horaria)\n",
    "- **atemp**: sensacion termica normalizada en grados centigrados. MinMax Scaler (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (solo en escala horaria)\n",
    "- **hum**: humedad normalizada, dividido entre 100 (max)\n",
    "- **windspeed**: velocidad del viento normalizada, dividido entre 67 (max)\n",
    "- **casual**: cuenta de usuarios casuales\n",
    "- **registered**: cuenta de usuarios registrados\n",
    "- **cnt**: cuenta total del alquiler de bicicletas, incluyendo tanto los casuales como los registrados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_df=pd.read_csv('data/hour.csv')  # datos por hora\n",
    "day_df=pd.read_csv('data/day.csv')    # datos por dia\n",
    "\n",
    "hour_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nos centraremos en los datos por hora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero se quitan dos columnas con info redundante...\n",
    "\n",
    "hour_df=hour_df.drop(columns=['casual', 'registered', 'workingday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info del dataframe, no hay nulos\n",
    "\n",
    "hour_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downcasting\n",
    "\n",
    "for e in hour_df.select_dtypes('integer').columns:\n",
    "    hour_df[e]=pd.to_numeric(hour_df[e], downcast='integer')\n",
    "\n",
    "for e in hour_df.select_dtypes('float').columns:\n",
    "    hour_df[e]=pd.to_numeric(hour_df[e], downcast='float')\n",
    "\n",
    "\n",
    "hour_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descripcion\n",
    "\n",
    "hour_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objetivo - cnt (cuenta)\n",
    "\n",
    "hour_df.cnt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_df.cnt.plot()\n",
    "plt.ylabel('# Alquileres', fontsize=12)\n",
    "plt.title('Registro Alquiler Bicicletas', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(hour_df.cnt))\n",
    "plt.ylabel('# ordenado de alquileres', fontsize=12)\n",
    "plt.title('Registro Alquiler Bicicletas (ordenado)', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**comparacion del objetivo con la variables numericas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuenta contra temperatura, sensacion termica, humedad y velocidad del viento\n",
    "\n",
    "count=0\n",
    "\n",
    "\n",
    "for t in hour_df.dtypes:\n",
    "    \n",
    "    if (t=='float32'):\n",
    "        hour_df=hour_df.sort_values(hour_df.dtypes.index[count])\n",
    "        feat=hour_df.dtypes.index[count]\n",
    "        \n",
    "        plt.scatter(hour_df[feat], hour_df.cnt)\n",
    "        plt.title('Cnt  vs  ' + feat)\n",
    "        plt.xlabel(feat)\n",
    "        plt.ylabel('# Alquileres')\n",
    "        plt.show();\n",
    "        \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**comparacion del objetivo con la variables categoricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por estacion del año\n",
    "\n",
    "df1=hour_df[['season','cnt']].groupby(['season']).sum().reset_index()\n",
    "\n",
    "df1.plot(kind='bar', legend=False, \n",
    "         title ='Alquiler de bicicletas por estacion', \n",
    "         stacked=True, \n",
    "         fontsize=12)\n",
    "\n",
    "plt.xlabel('Estacion', fontsize=12)\n",
    "plt.ylabel('# Alquileres', fontsize=12)\n",
    "plt.xticks(range(4), \n",
    "           ['primavera','verano','otoño','invierno'], \n",
    "           rotation=45)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segun clima\n",
    "\n",
    "df2=hour_df[['weathersit','cnt']].groupby(['weathersit']).sum().reset_index()\n",
    "\n",
    "df2.plot(kind='bar', legend=False, \n",
    "         title ='Alquiler de bicicletas segun clima', \n",
    "         stacked=True, \n",
    "         fontsize=12)\n",
    "\n",
    "plt.xlabel('Clima', fontsize=12)\n",
    "plt.ylabel('# Alquileres', fontsize=12)\n",
    "plt.xticks(range(4), \n",
    "           ['despejado','nublado','lluvia ligera','lluvia fuerte'], \n",
    "           rotation=45)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por horas\n",
    "\n",
    "df3=hour_df[['hr','cnt']].groupby(['hr']).sum().reset_index()\n",
    "\n",
    "df3.plot(kind='bar', legend=False, \n",
    "         title ='Alquiler de bicicletas por hora del dia', \n",
    "         stacked=True, \n",
    "         fontsize=12)\n",
    "\n",
    "plt.xlabel('Hora', fontsize=12)\n",
    "plt.ylabel('# Alquileres', fontsize=12)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por mes\n",
    "\n",
    "df3=hour_df[['mnth','cnt']].groupby(['mnth']).sum().reset_index()\n",
    "\n",
    "df3.plot(kind='bar', legend=False, \n",
    "         title ='Alquiler de bicicletas por mes', \n",
    "         stacked=True, \n",
    "         fontsize=12)\n",
    "\n",
    "plt.xlabel('Mes', fontsize=12)\n",
    "plt.ylabel('# Alquileres', fontsize=12)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**primero statsmodels para ver significancia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=hour_df.drop(columns=['cnt', 'instant', 'dteday'])  # datos\n",
    "y=hour_df.cnt                  # objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=sm.OLS(y, X).fit()\n",
    "pred=modelo.predict(X)\n",
    "\n",
    "\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A traves de los p-values, podemos ver que el mes lo podriamos quitar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**split de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=hour_df.drop(columns=['cnt', 'instant', 'dteday', 'mnth'])  \n",
    "y=hour_df.cnt                  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresion Lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg=LinReg()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred=linreg.predict(X_test)\n",
    "\n",
    "print ('RMSE = {:.2f}'.format(mse(y_test, y_pred)**.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polinomios de grado 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly=PF(2)\n",
    "X_train_pf2=poly.fit_transform(X_train)\n",
    "X_test_pf2=poly.fit_transform(X_test)\n",
    "\n",
    "linreg.fit(X_train_pf2, y_train)\n",
    "\n",
    "y_pred=linreg.predict(X_test_pf2)\n",
    "\n",
    "print ('RMSE = {:.2f}'.format(mse(y_test, y_pred)**.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polinomios de grado 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly=PF(3)\n",
    "X_train_pf3=poly.fit_transform(X_train)\n",
    "X_test_pf3=poly.fit_transform(X_test)\n",
    "\n",
    "linreg.fit(X_train_pf3, y_train)\n",
    "\n",
    "y_pred=linreg.predict(X_test_pf3)\n",
    "\n",
    "print ('RMSE = {:.2f}'.format(mse(y_test, y_pred)**.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**one hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy=pd.get_dummies(X_train, \n",
    "                       columns=['season', 'weekday', 'weathersit'], \n",
    "                       drop_first=False)\n",
    "X_train_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dummy=pd.get_dummies(X_test, \n",
    "                       columns=['season', 'weekday', 'weathersit'], \n",
    "                       drop_first=False)\n",
    "X_test_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train_dummy, y_train)\n",
    "\n",
    "y_pred=linreg.predict(X_test_dummy)\n",
    "\n",
    "print ('RMSE = {:.2f}'.format(mse(y_test, y_pred)**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coeficientes: \\n', linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ordenada en el origen \\n', linreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**probando gradient boosting regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr=GBR()\n",
    "gbr.fit(X_train_dummy, np.ravel(y_train))\n",
    "\n",
    "y_pred=gbr.predict(X_test_dummy)\n",
    "\n",
    "print ('RMSE = {:.2f}'.format(mse(y_test, y_pred)**.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado temporal\n",
    "\n",
    "Se usa la hora anterior (suma de alquileres) para predecir la siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horas\n",
    "df5=hour_df[['dteday','hr','cnt']].groupby(['dteday','hr']).sum().reset_index()\n",
    "df5.sort_values(['dteday','hr'])\n",
    "\n",
    "# se tienen en consideracion dos horas atras\n",
    "df5['sum_hr_1']=df5.cnt.shift(+1)\n",
    "df5['sum_hr_2']=df5.cnt.shift(+2)\n",
    "\n",
    "\n",
    "merged=pd.merge(hour_df, df5[['dteday', 'hr', \n",
    "                              'sum_hr_1', \n",
    "                              'sum_hr_2']], \n",
    "                how='inner', \n",
    "                on=['dteday', 'hr']).dropna()\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=merged.drop(columns=['cnt', 'instant', 'dteday', 'mnth'])  \n",
    "y=merged.cnt                  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time gbr.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred=gbr.predict(X_test)\n",
    "\n",
    "print ('RMSE = {:.2f}'.format(mse(y_test, y_pred)**.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pasos que se van a seguir con los datos:**\n",
    "\n",
    "- **modelado temporal**\n",
    "- **one-hot**\n",
    "- **seleccion de caracteristicas** : \n",
    "- **train_test_split** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_temp(df):\n",
    "    \n",
    "    m_df=df[['dteday','hr','cnt']].groupby(['dteday','hr']).sum().reset_index()\n",
    "    m_df.sort_values(['dteday','hr'])\n",
    "    \n",
    "    m_df['sum_hr_1']=m_df.cnt.shift(+1)\n",
    "    m_df['sum_hr_2']=m_df.cnt.shift(+2)\n",
    "    \n",
    "    merged=pd.merge(df, m_df[['dteday', 'hr', \n",
    "                              'sum_hr_1', \n",
    "                              'sum_hr_2']], \n",
    "                    how='inner', \n",
    "                    on=['dteday', 'hr']).dropna()\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df):\n",
    "   return pd.get_dummies(df, \n",
    "                   columns=['season', 'weekday', 'weathersit'], \n",
    "                   drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_split(df, test_size=0.2):\n",
    "    X=df.drop(columns=['instant', 'dteday', 'mnth',\n",
    "                       'workingday', 'cnt', 'casual', 'registered'])\n",
    "    y=df.cnt\n",
    "    \n",
    "    return train_test_split(X, y, test_size=test_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion (R2, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/hour.csv')  \n",
    "df=mod_temp(df)\n",
    "df=one_hot(df)\n",
    "X_train, X_test, y_train, y_test=sel_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg=LinReg()\n",
    "\n",
    "\n",
    "for e in X_train.columns:\n",
    "    linreg.fit(X_train[[e]], y_train)\n",
    "    y_pred=linreg.predict(X_test[[e]])\n",
    "    \n",
    "    print ('R^2 para {} es {:.2f}'.format(e, r2_score(y_test, y_pred)))\n",
    "    print ('RMSE para {} = {:.2f}'.format(e, mse(y_test, y_pred)**.5))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**coeficientes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred=linreg.predict(X_test)\n",
    " \n",
    "# root mean squared error\n",
    "print ('RMSE = {:.2f}'.format(mse(y_test, y_pred)**.5))\n",
    "print ()\n",
    "print ('Intercept = {}'.format(linreg.intercept_))\n",
    " \n",
    "coefs=pd.DataFrame({'coeficientes':linreg.coef_, \n",
    "                    'caracteristica':X_train.columns.values})\\\n",
    "                    .sort_values('coeficientes').reset_index()\\\n",
    "                    .drop('index', axis=1)\n",
    "\n",
    "\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo para Web-App (main.py)\n",
    "\n",
    "El modelo va a estar basado en la temperatura, estacion del año, si es fiesta o no y la hora del dia.\n",
    "\n",
    "\n",
    "**Preparacion de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion auxiliar para cargar los datos\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "import pandas as pd\n",
    "\n",
    "def data():\n",
    "    df=pd.read_csv('data/hour.csv')\n",
    "    \n",
    "    m_df=df[['dteday','hr','cnt']].groupby(['dteday','hr']).sum().reset_index()\n",
    "    m_df.sort_values(['dteday','hr'])\n",
    "    m_df['sum_hr_1']=m_df.cnt.shift(+1)\n",
    "    m_df['sum_hr_2']=m_df.cnt.shift(+2)\n",
    "    \n",
    "    merged=pd.merge(df, m_df[['dteday', 'hr', \n",
    "                              'sum_hr_1', \n",
    "                              'sum_hr_2']], \n",
    "                    how='inner', \n",
    "                    on=['dteday', 'hr']).dropna()\n",
    "    \n",
    "    \n",
    "    dummy=pd.get_dummies(merged, \n",
    "                         columns=['season', 'weekday', 'weathersit'], \n",
    "                         drop_first=False)\n",
    "    \n",
    "    \n",
    "    X=dummy.drop(columns=['instant', 'dteday', 'mnth',\n",
    "                          'workingday', 'cnt', 'casual', \n",
    "                          'registered'])\n",
    "    y=dummy.cnt\n",
    "    \n",
    "    linreg=LinReg().fit(X,y)\n",
    "    \n",
    "    coefs=pd.DataFrame({'coef':linreg.coef_, \n",
    "                        'carac':X_train.columns.values})\\\n",
    "                        .sort_values('coef').reset_index()\\\n",
    "                        .drop('index', axis=1)\n",
    "    coefs=coefs.append({'coef':linreg.intercept_, \n",
    "                        'carac':'intercept'},\n",
    "                       ignore_index=True)\n",
    "    \n",
    "    coefs.to_csv('data/coefs.csv') \n",
    "    X.describe().T['mean'].to_csv('data/means.csv')\n",
    "\n",
    "    \n",
    "data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "from flask import Flask\n",
    "from flask import render_template\n",
    "from flask import flash\n",
    "from flask import request\n",
    "from flask import jsonify\n",
    "from flask import Markup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "    \n",
    "# inicia Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "    \n",
    "# coeficientes\n",
    "coefs=None\n",
    "\n",
    "\n",
    "# valores medios como datos de entrada\n",
    "input_data=None\n",
    "\n",
    "\n",
    "@app.before_first_request\n",
    "def startup():\n",
    "    global coefs\n",
    "    coefs=pd.read_csv('data/coefs.csv')\\\n",
    "            .set_index('carac')\\\n",
    "            .to_dict()['coef']\n",
    "    \n",
    "    global input_data\n",
    "    input_data=pd.read_csv('data/means.csv', names=['carac', 'coef'])\\\n",
    "                 .set_index('carac')\\\n",
    "                 .to_dict()['coef']\n",
    "    \n",
    "\n",
    "# cuando carga, son los valores por defecto\n",
    "# se va a predecir sobre 4 caracteristicas, pero se necesita evaluar\n",
    "# con todas.\n",
    "@app.route(\"/\", methods=['POST', 'GET'])\n",
    "def index():\n",
    "    return render_template('index.html',\n",
    "                           \n",
    "            holiday=input_data['holiday'],\n",
    "            hr=input_data['hr'],\n",
    "            yr=input_data['yr'],\n",
    "            hum=input_data['hum'],\n",
    "            temp=input_data['temp'],\n",
    "            atemp=input_data['atemp'],\n",
    "            windspeed=input_data['windspeed'],\n",
    "            season_1=1,\n",
    "            season_2=0,\n",
    "            season_3=0,\n",
    "            season_4=0,\n",
    "            weathersit_1=input_data['weathersit_1'],\n",
    "            weathersit_2=input_data['weathersit_2'],\n",
    "            weathersit_3=input_data['weathersit_3'],\n",
    "            weathersit_4=input_data['weathersit_4'],\n",
    "            weekday_1=input_data['weekday_1'],\n",
    "            weekday_2=input_data['weekday_2'],\n",
    "            weekday_3=input_data['weekday_3'],\n",
    "            weekday_4=input_data['weekday_4'],\n",
    "            weekday_5=input_data['weekday_5'],\n",
    "            weekday_6=input_data['weekday_6'],\n",
    "            weekday_0=input_data['weekday_0'],\n",
    "            sum_hr_1=input_data['sum_hr_1'],\n",
    "            sum_hr_2=input_data['sum_hr_2'],\n",
    "                        \n",
    "                           \n",
    "            coef_intercept=coefs['intercept'],\n",
    "            coef_holiday=coefs['holiday'],\n",
    "            coef_hr=coefs['hr'],\n",
    "            coef_yr=coefs['yr'],\n",
    "            coef_hum=coefs['hum'],\n",
    "            coef_temp=coefs['temp'],\n",
    "            coef_atemp=coefs['atemp'],\n",
    "            coef_windspeed=coefs['windspeed'],\n",
    "            coef_season_1=coefs['season_1'],\n",
    "            coef_season_2=coefs['season_2'],\n",
    "            coef_season_3=coefs['season_3'],\n",
    "            coef_season_4=coefs['season_4'],\n",
    "            coef_weathersit_1=coefs['weathersit_1'],\n",
    "            coef_weathersit_2=coefs['weathersit_2'],\n",
    "            coef_weathersit_3=coefs['weathersit_3'],\n",
    "            coef_weathersit_4=coefs['weathersit_4'],\n",
    "            coef_weekday_1=coefs['weekday_1'],\n",
    "            coef_weekday_2=coefs['weekday_2'],\n",
    "            coef_weekday_3=coefs['weekday_3'],\n",
    "            coef_weekday_4=coefs['weekday_4'],\n",
    "            coef_weekday_5=coefs['weekday_5'],\n",
    "            coef_weekday_6=coefs['weekday_6'],\n",
    "            coef_weekday_0=coefs['weekday_0'],\n",
    "            coef_sum_hr_1=coefs['sum_hr_1'],\n",
    "            coef_sum_hr_2=coefs['sum_hr_2'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# para ejecutar en local\n",
    "if __name__=='__main__':\n",
    "      app.run(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codigo HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('data/coefs.csv')\\\n",
    "            .set_index('carac')\\\n",
    "            .to_dict()['coef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
